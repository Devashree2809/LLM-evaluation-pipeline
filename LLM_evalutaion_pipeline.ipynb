{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CChSncMZtsfJ"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import time\n",
        "import math\n",
        "from typing import List\n",
        "\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    dot = sum(a * b for a, b in zip(vec1, vec2))\n",
        "    norm1 = math.sqrt(sum(a * a for a in vec1))\n",
        "    norm2 = math.sqrt(sum(b * b for b in vec2))\n",
        "    return dot / (norm1 * norm2 + 1e-8)\n",
        "\n",
        "def split_sentences(text: str) -> List[str]:\n",
        "    return [s.strip() for s in text.split('.') if s.strip()]\n",
        "\n",
        "def get_embedding(text: str) -> List[float]:\n",
        "    return [float((hash(text) >> i) & 1) for i in range(64)]\n",
        "\n",
        "def llm_completeness_judge(question: str, answer: str) -> float:\n",
        "    return 0.75 if len(answer) > len(question) else 0.4\n",
        "\n",
        "def llm_fact_checker(answer: str, context: str) -> float:\n",
        "    return 0.1\n",
        "\n",
        "def evaluate_relevance(user_query, ai_response):\n",
        "    emb_q = get_embedding(user_query)\n",
        "    emb_a = get_embedding(ai_response)\n",
        "    return cosine_similarity(emb_q, emb_a)\n",
        "\n",
        "def evaluate_completeness(user_query, ai_response):\n",
        "    keywords = set(user_query.lower().split())\n",
        "    answer_words = set(ai_response.lower().split())\n",
        "\n",
        "    coverage = len(keywords & answer_words) / max(len(keywords), 1)\n",
        "    length_ratio = len(ai_response) / max(len(user_query), 1)\n",
        "\n",
        "    heuristic_score = min(1.0, 0.5 * coverage + 0.5 * min(1, length_ratio / 2))\n",
        "\n",
        "    if heuristic_score >= 0.7:\n",
        "        return heuristic_score, \"heuristic\"\n",
        "    else:\n",
        "        return llm_completeness_judge(user_query, ai_response), \"llm\"\n",
        "\n",
        "def evaluate_hallucination(ai_response, context_text):\n",
        "    sentences = split_sentences(ai_response)\n",
        "    unsupported = 0\n",
        "\n",
        "    emb_context = get_embedding(context_text)\n",
        "\n",
        "    for s in sentences:\n",
        "        emb_s = get_embedding(s)\n",
        "        sim = cosine_similarity(emb_s, emb_context)\n",
        "        if sim < 0.55:\n",
        "            unsupported += 1\n",
        "\n",
        "    hallucination_ratio = unsupported / max(len(sentences), 1)\n",
        "\n",
        "    if hallucination_ratio > 0.2:\n",
        "        return llm_fact_checker(ai_response, context_text), \"llm\"\n",
        "    else:\n",
        "        return hallucination_ratio, \"embedding\"\n",
        "\n",
        "def estimate_cost(embedding_calls, llm_calls):\n",
        "    EMBED_COST = 0.00001\n",
        "    LLM_COST = 0.001\n",
        "    return embedding_calls * EMBED_COST + llm_calls * LLM_COST\n",
        "\n",
        "def evaluate_response(conversation_json, context_json):\n",
        "    start_time = time.time()\n",
        "\n",
        "    user_query = \"\"\n",
        "    ai_response = \"\"\n",
        "\n",
        "    for msg in conversation_json[\"conversation\"]:\n",
        "        if msg[\"role\"] == \"user\":\n",
        "            user_query = msg[\"content\"]\n",
        "        elif msg[\"role\"] == \"assistant\":\n",
        "            ai_response = msg[\"content\"]\n",
        "\n",
        "    context_text = \" \".join(context_json[\"context_chunks\"])\n",
        "\n",
        "    embedding_calls = 0\n",
        "    llm_calls = 0\n",
        "\n",
        "    relevance_score = evaluate_relevance(user_query, ai_response)\n",
        "    embedding_calls += 2\n",
        "\n",
        "    if relevance_score < 0.6:\n",
        "        return {\n",
        "            \"final_verdict\": \"FAIL\",\n",
        "            \"reason\": \"Irrelevant answer\"\n",
        "        }\n",
        "\n",
        "    completeness_score, comp_method = evaluate_completeness(user_query, ai_response)\n",
        "    if comp_method == \"llm\":\n",
        "        llm_calls += 1\n",
        "\n",
        "    hallucination_score, hall_method = evaluate_hallucination(ai_response, context_text)\n",
        "    embedding_calls += len(split_sentences(ai_response)) + 1\n",
        "    if hall_method == \"llm\":\n",
        "        llm_calls += 1\n",
        "\n",
        "    latency_ms = int((time.time() - start_time) * 1000)\n",
        "    cost_usd = estimate_cost(embedding_calls, llm_calls)\n",
        "\n",
        "    if hallucination_score > 0.2:\n",
        "        verdict = \"FAIL\"\n",
        "    elif completeness_score < 0.6:\n",
        "        verdict = \"WARN\"\n",
        "    else:\n",
        "        verdict = \"PASS\"\n",
        "\n",
        "    return {\n",
        "        \"relevance_score\": round(relevance_score, 2),\n",
        "        \"completeness_score\": round(completeness_score, 2),\n",
        "        \"hallucination_score\": round(hallucination_score, 2),\n",
        "        \"latency_ms\": latency_ms,\n",
        "        \"cost_usd\": round(cost_usd, 5),\n",
        "        \"final_verdict\": verdict\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08726154",
        "outputId": "80eb9707-5a83-4565-8e29-2bbfd607f5c7"
      },
      "source": [
        "conversation_json = {\n",
        "    \"conversation\": [\n",
        "        {\n",
        "            \"turn\": 1,\n",
        "            \"sender_id\": 1,\n",
        "            \"role\": \"AI/Chatbot\",\n",
        "            \"content\": \"I know what you're going through. Let's talk. I'm here to support you for all your infertility and IVF needs. Please tell me what's on your mind.\",\n",
        "            \"created_at\": \"2025-11-16T17:04:44.000000Z\"\n",
        "        },\n",
        "        {\n",
        "            \"turn\": 5,\n",
        "            \"sender_id\": 77096,\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"I and my wife are planning to come to India early next month. I am still trying to convince her that since I started with communicating with you eversince, I may be a good idea to come to you in an attempt to solve our infertility problems.\",\n",
        "            \"created_at\": \"2025-11-16T17:06:58.000000Z\"\n",
        "        },\n",
        "        {\n",
        "            \"turn\": 6,\n",
        "            \"sender_id\": 1,\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": \"It's wonderful to hear you are planning to come to India and are considering us. We are here to support you.\",\n",
        "            \"created_at\": \"2025-11-16T17:07:30.000000Z\"\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "context_json = {\n",
        "    \"context_chunks\": [\n",
        "        \"Infertility treatment options in India include IVF, ICSI, IUI, and other assisted reproductive technologies.\",\n",
        "        \"Many couples travel to India for fertility treatments due to advanced medical facilities and experienced specialists.\",\n",
        "        \"Success rates for IVF in India are comparable to international standards.\",\n",
        "        \"Planning your trip involves understanding visa requirements, accommodation, and local transport.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Now, call the evaluate_response function with these inputs\n",
        "result = evaluate_response(conversation_json, context_json)\n",
        "print(result)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'final_verdict': 'FAIL', 'reason': 'Irrelevant answer'}\n"
          ]
        }
      ]
    }
  ]
}